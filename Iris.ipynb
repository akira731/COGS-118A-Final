{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23371516-abd6-460e-9a1d-481be2e8c5ae",
   "metadata": {},
   "source": [
    "## Iris Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a6eefe8-2929-4fca-bb22-912496e600e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fbf8ad8e-9b12-4c61-a71e-b02a62a24a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'iris.data'\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f37e218d-d473-499e-a056-735bfdf7fe50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset preview;\n",
      "   5.1  3.5  1.4  0.2  Iris-setosa\n",
      "0  4.9  3.0  1.4  0.2  Iris-setosa\n",
      "1  4.7  3.2  1.3  0.2  Iris-setosa\n",
      "2  4.6  3.1  1.5  0.2  Iris-setosa\n",
      "3  5.0  3.6  1.4  0.2  Iris-setosa\n",
      "4  5.4  3.9  1.7  0.4  Iris-setosa\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataset preview;\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "672eb18f-f25a-4764-8f61-5bbd492cdadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = ['sepal_length' , 'sepal_width', 'petal_length', 'petal_width', 'species']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe10e833-39ee-4ee7-9525-b5499f8a5889",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed dataset preview:\n",
      "   sepal_length  sepal_width  petal_length  petal_width  Label\n",
      "0           4.9          3.0           1.4          0.2      1\n",
      "1           4.7          3.2           1.3          0.2      1\n",
      "2           4.6          3.1           1.5          0.2      1\n",
      "3           5.0          3.6           1.4          0.2      1\n",
      "4           5.4          3.9           1.7          0.4      1\n"
     ]
    }
   ],
   "source": [
    "df['Label'] = df['species'].apply(lambda x: 1 if x == 'Iris-setosa' else 0)\n",
    "\n",
    "df = df.drop(columns=['species'])\n",
    "\n",
    "# Separate features\n",
    "X = df.drop(columns=['Label']).values\n",
    "y = df['Label'].values\n",
    "\n",
    "# Display \n",
    "print(\"\\nProcessed dataset preview:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8209e478-066f-4026-892b-9babf1262764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/20 Split:\n",
      "Training samples: 119, Testing samples: 30\n",
      "\n",
      "50/50 Split:\n",
      "Training samples: 74, Testing samples: 75\n",
      "\n",
      "20/80 Split:\n",
      "Training samples: 29, Testing samples: 120\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Separate features and labels\n",
    "X = df.drop(columns=['Label']).values\n",
    "y = df['Label'].values\n",
    "\n",
    "# Create 80/20 split\n",
    "X_train_80, X_test_80, y_train_80, y_test_80 = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(\"80/20 Split:\")\n",
    "print(f\"Training samples: {len(X_train_80)}, Testing samples: {len(X_test_80)}\")\n",
    "\n",
    "# Create 50/50 split\n",
    "X_train_50, X_test_50, y_train_50, y_test_50 = train_test_split(X, y, test_size=0.5, random_state=42)\n",
    "print(\"\\n50/50 Split:\")\n",
    "print(f\"Training samples: {len(X_train_50)}, Testing samples: {len(X_test_50)}\")\n",
    "\n",
    "# Create 20/80 split\n",
    "X_train_20, X_test_20, y_train_20, y_test_20 = train_test_split(X, y, test_size=0.8, random_state=42)\n",
    "print(\"\\n20/80 Split:\")\n",
    "print(f\"Training samples: {len(X_train_20)}, Testing samples: {len(X_test_20)}\")\n",
    "\n",
    "# Organize splits into a dictionary \n",
    "splits = {\n",
    "    \"80/20\": (X_train_80, X_test_80, y_train_80, y_test_80),\n",
    "    \"50/50\": (X_train_50, X_test_50, y_train_50, y_test_50),\n",
    "    \"20/80\": (X_train_20, X_test_20, y_train_20, y_test_20)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4585f5e5-5083-4340-9793-0bb3ec8c6a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Initialize classifiers\n",
    "classifiers = {\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'SVM': SVC(kernel='rbf', C=1, gamma='scale', random_state=42),\n",
    "    'KNN': KNeighborsClassifier(n_neighbors=5)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "43243776-bccd-4e30-a4a5-a3aded3cd6d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Conducting trials for 80/20 partition:\n",
      "  Trial 1:\n",
      "    Random Forest - Accuracy: 1.0000\n",
      "    SVM - Accuracy: 1.0000\n",
      "    KNN - Accuracy: 1.0000\n",
      "  Trial 2:\n",
      "    Random Forest - Accuracy: 1.0000\n",
      "    SVM - Accuracy: 1.0000\n",
      "    KNN - Accuracy: 1.0000\n",
      "  Trial 3:\n",
      "    Random Forest - Accuracy: 1.0000\n",
      "    SVM - Accuracy: 1.0000\n",
      "    KNN - Accuracy: 1.0000\n",
      "\n",
      "Conducting trials for 50/50 partition:\n",
      "  Trial 1:\n",
      "    Random Forest - Accuracy: 1.0000\n",
      "    SVM - Accuracy: 1.0000\n",
      "    KNN - Accuracy: 1.0000\n",
      "  Trial 2:\n",
      "    Random Forest - Accuracy: 1.0000\n",
      "    SVM - Accuracy: 1.0000\n",
      "    KNN - Accuracy: 1.0000\n",
      "  Trial 3:\n",
      "    Random Forest - Accuracy: 1.0000\n",
      "    SVM - Accuracy: 1.0000\n",
      "    KNN - Accuracy: 1.0000\n",
      "\n",
      "Conducting trials for 20/80 partition:\n",
      "  Trial 1:\n",
      "    Random Forest - Accuracy: 1.0000\n",
      "    SVM - Accuracy: 1.0000\n",
      "    KNN - Accuracy: 1.0000\n",
      "  Trial 2:\n",
      "    Random Forest - Accuracy: 1.0000\n",
      "    SVM - Accuracy: 1.0000\n",
      "    KNN - Accuracy: 1.0000\n",
      "  Trial 3:\n",
      "    Random Forest - Accuracy: 1.0000\n",
      "    SVM - Accuracy: 1.0000\n",
      "    KNN - Accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Number of trials\n",
    "num_trials = 3\n",
    "\n",
    "# Store results\n",
    "results = {}\n",
    "\n",
    "for partition_name, (X_train_orig, X_test_orig, y_train_orig, y_test_orig) in splits.items():\n",
    "    results[partition_name] = {clf_name: [] for clf_name in classifiers.keys()}\n",
    "    print(f\"\\nConducting trials for {partition_name} partition:\")\n",
    "    \n",
    "    for trial in range(num_trials):\n",
    "        print(f\"  Trial {trial + 1}:\")\n",
    "        # Shuffle the dataset with a different random state\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            np.vstack((X_train_orig, X_test_orig)),\n",
    "            np.hstack((y_train_orig, y_test_orig)),\n",
    "            test_size=len(X_test_orig) / (len(X_train_orig) + len(X_test_orig)),\n",
    "            random_state=trial\n",
    "        )\n",
    "        \n",
    "        for clf_name, clf in classifiers.items():\n",
    "            # Train the classifier\n",
    "            clf.fit(X_train, y_train)\n",
    "            \n",
    "            # Test the classifier\n",
    "            y_pred = clf.predict(X_test)\n",
    "            \n",
    "            # Calculate accuracy\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            results[partition_name][clf_name].append(accuracy)\n",
    "            print(f\"    {clf_name} - Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a7b9a7db-d439-4b4e-a8d0-631f120fba68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Define hyperparameter grids\n",
    "param_grids = {\n",
    "    'Random Forest': {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'max_depth': [None, 10, 20, 30],\n",
    "        'min_samples_split': [2, 5, 10]\n",
    "    },\n",
    "    'SVM': {\n",
    "        'C': [0.1, 1, 10, 100],\n",
    "        'gamma': ['scale', 0.1, 0.01, 0.001],\n",
    "        'kernel': ['rbf']\n",
    "    },\n",
    "    'KNN': {\n",
    "        'n_neighbors': range(3, 11),\n",
    "        'weights': ['uniform', 'distance'],\n",
    "        'p': [1, 2]  # Manhattan (1) and Euclidean (2)\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "67d211b5-9bea-47dd-a132-e9c2ab1d2eba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Hyperparameter tuning for 80/20 partition:\n",
      "\n",
      "Tuning Random Forest...\n",
      "Best parameters for Random Forest: {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 50}\n",
      "Best cross-validation accuracy for Random Forest: 1.0000\n",
      "\n",
      "Tuning SVM...\n",
      "Best parameters for SVM: {'C': 0.1, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "Best cross-validation accuracy for SVM: 1.0000\n",
      "\n",
      "Tuning KNN...\n",
      "Best parameters for KNN: {'n_neighbors': 3, 'p': 1, 'weights': 'uniform'}\n",
      "Best cross-validation accuracy for KNN: 1.0000\n",
      "\n",
      "Hyperparameter tuning for 50/50 partition:\n",
      "\n",
      "Tuning Random Forest...\n",
      "Best parameters for Random Forest: {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 50}\n",
      "Best cross-validation accuracy for Random Forest: 1.0000\n",
      "\n",
      "Tuning SVM...\n",
      "Best parameters for SVM: {'C': 0.1, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "Best cross-validation accuracy for SVM: 1.0000\n",
      "\n",
      "Tuning KNN...\n",
      "Best parameters for KNN: {'n_neighbors': 3, 'p': 1, 'weights': 'uniform'}\n",
      "Best cross-validation accuracy for KNN: 1.0000\n",
      "\n",
      "Hyperparameter tuning for 20/80 partition:\n",
      "\n",
      "Tuning Random Forest...\n",
      "Best parameters for Random Forest: {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 50}\n",
      "Best cross-validation accuracy for Random Forest: 1.0000\n",
      "\n",
      "Tuning SVM...\n",
      "Best parameters for SVM: {'C': 1, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "Best cross-validation accuracy for SVM: 1.0000\n",
      "\n",
      "Tuning KNN...\n",
      "Best parameters for KNN: {'n_neighbors': 3, 'p': 1, 'weights': 'uniform'}\n",
      "Best cross-validation accuracy for KNN: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Store results for hyperparameter tuning\n",
    "best_params = {}\n",
    "partition_results = {}\n",
    "\n",
    "# Perform GridSearchCV for each partition and classifier\n",
    "for partition_name, (X_train, X_test, y_train, y_test) in splits.items():\n",
    "    print(f\"\\nHyperparameter tuning for {partition_name} partition:\")\n",
    "    partition_results[partition_name] = {}\n",
    "    best_params[partition_name] = {}\n",
    "    \n",
    "    for clf_name, clf in {'Random Forest': RandomForestClassifier(random_state=42),\n",
    "                          'SVM': SVC(random_state=42),\n",
    "                          'KNN': KNeighborsClassifier()}.items():\n",
    "        \n",
    "        print(f\"\\nTuning {clf_name}...\")\n",
    "        \n",
    "        # Initialize GridSearchCV\n",
    "        grid_search = GridSearchCV(\n",
    "            clf,\n",
    "            param_grid=param_grids[clf_name],\n",
    "            cv=5,  # 5-fold cross-validation\n",
    "            scoring='accuracy',\n",
    "            n_jobs=-1  # Use all processors\n",
    "        )\n",
    "        \n",
    "        # Fit GridSearchCV\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        \n",
    "        # Store the best parameters and corresponding accuracy\n",
    "        best_params[partition_name][clf_name] = grid_search.best_params_\n",
    "        partition_results[partition_name][clf_name] = grid_search.best_score_\n",
    "        \n",
    "        print(f\"Best parameters for {clf_name}: {grid_search.best_params_}\")\n",
    "        print(f\"Best cross-validation accuracy for {clf_name}: {grid_search.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1207c3f1-132e-4968-8b30-2d0fc257a27e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d8d2fb-8db0-4a05-a5e4-ca8d50d1bc66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
